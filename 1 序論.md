## 0.序論
### 教師なし学習
* クラスタリング
* 密度推定: 入力空間におけるデータの分布を求める
* 視覚化: 高次元のデータを2~3次元に射影

#### 密度推定
有限の標本点から（各標本点はなんらかの関数に従い生成されていると仮定し、その隠されたパラメータを推定することで）標本点の存在しない全体の分布を推定すること

### 1.1 多項式曲線フィッティング
* データは学習しようとする規則性を保持しているが、観測値には何らかのランダムノイズが混在している
* 多項式曲線フィッティングでは次数を増やす（=モデルの表現力を高める）と過学習が発生する
* 過学習は自由度の高い多項式（=表現力の高いモデル）がランダムノイズに引きずられている状態
* 過学習の対策としてはデータ数を増やす（=ランダムノイズの影響が低減される） or 正則化 or ベイズ的アプローチ
* 正則化する場合には正則化項の最適なパラメータを検証する必要がある

#### 正則化
* 1次の正則化（Lasso回帰）: (余分なパラメータが0となるため)次元圧縮
* 2次の正則化（Ridge回帰）: Lasso回帰よりは精度が高い

### 本章の用語
以下の用語は意味を把握すること
* 周辺確率
* 確率密度
* 累積分布関数
* 確率質量関数
